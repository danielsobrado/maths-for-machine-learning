{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7cf6cd",
   "metadata": {},
   "source": [
    "# Bayesian Statistics for Machine Learning\n",
    "## Uncertainty Estimation and Probabilistic Models\n",
    "\n",
    "Welcome to the **science of reasoning under uncertainty**! Bayesian statistics provides the mathematical framework for incorporating prior knowledge and updating beliefs as new evidence arrives.\n",
    "\n",
    "### What You'll Master\n",
    "By the end of this notebook, you'll understand:\n",
    "1. **Bayes' theorem** - The foundation of probabilistic reasoning\n",
    "2. **Prior and posterior distributions** - Encoding and updating beliefs\n",
    "3. **Bayesian inference** - Learning from data with uncertainty\n",
    "4. **Conjugate priors** - Mathematical convenience in Bayesian analysis\n",
    "5. **MCMC methods** - Sampling from complex distributions\n",
    "6. **Bayesian neural networks** - Deep learning with uncertainty\n",
    "\n",
    "### Why This is Revolutionary\n",
    "- **Uncertainty quantification** - Know how confident your model is\n",
    "- **Prior knowledge** - Incorporate domain expertise\n",
    "- **Small data learning** - Make inferences with limited samples\n",
    "- **Model selection** - Compare models probabilistically\n",
    "\n",
    "### Real-World Applications\n",
    "- **Medical diagnosis**: Updating disease probability with test results\n",
    "- **A/B testing**: Deciding which variant is better\n",
    "- **Autonomous vehicles**: Reasoning about uncertain environments\n",
    "- **Finance**: Portfolio optimization under uncertainty\n",
    "\n",
    "Let's embrace uncertainty and turn it into knowledge! ðŸŽ²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdff35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, beta, gamma, poisson, binom, uniform\n",
    "from scipy.optimize import minimize_scalar\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"ðŸŽ² Bayesian Statistics toolkit loaded!\")\n",
    "print(\"Ready to reason under uncertainty!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222291c6",
   "metadata": {},
   "source": [
    "## 1. Bayes' Theorem: The Foundation\n",
    "\n",
    "### The Most Important Equation in Statistics\n",
    "```\n",
    "P(Î¸|D) = P(D|Î¸) Ã— P(Î¸) / P(D)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- **P(Î¸|D)**: Posterior - What we believe after seeing data\n",
    "- **P(D|Î¸)**: Likelihood - How probable the data is given our hypothesis\n",
    "- **P(Î¸)**: Prior - What we believed before seeing data\n",
    "- **P(D)**: Evidence - Total probability of observing the data\n",
    "\n",
    "### The Bayesian Philosophy\n",
    "1. **Start with prior beliefs** (even if uninformative)\n",
    "2. **Observe data** and calculate likelihood\n",
    "3. **Update beliefs** to get posterior distribution\n",
    "4. **Quantify uncertainty** throughout the process\n",
    "\n",
    "### Bayesian vs Frequentist\n",
    "| Aspect | Bayesian | Frequentist |\n",
    "|--------|----------|-------------|\n",
    "| Parameters | Random variables | Fixed constants |\n",
    "| Probability | Degree of belief | Long-run frequency |\n",
    "| Inference | Posterior distribution | Point estimates + confidence intervals |\n",
    "| Prior knowledge | Explicitly incorporated | Implicitly ignored |\n",
    "\n",
    "### Real-World Analogy\n",
    "Think of Bayes' theorem as **detective work**:\n",
    "- **Prior**: Your initial suspicion about the suspect\n",
    "- **Likelihood**: How well the evidence fits your theory\n",
    "- **Posterior**: Your updated belief after considering evidence\n",
    "- **Evidence**: All possible explanations for what you observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c1e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_bayes_theorem():\n",
    "    \"\"\"Explore Bayes' theorem with classic examples\"\"\"\n",
    "    \n",
    "    print(\"ðŸŽ¯ Bayes' Theorem: Updating Beliefs with Evidence\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Medical diagnosis example\n",
    "    print(\"\\n1. Medical Diagnosis: The Base Rate Fallacy\")\n",
    "    print(\"   Disease prevalence: 1 in 1000 people\")\n",
    "    print(\"   Test accuracy: 99% (both sensitivity and specificity)\")\n",
    "    print(\"   Question: If you test positive, what's P(disease)?\")\n",
    "    \n",
    "    # Prior probability\n",
    "    p_disease = 0.001\n",
    "    p_no_disease = 1 - p_disease\n",
    "    \n",
    "    # Likelihood\n",
    "    p_positive_given_disease = 0.99  # Sensitivity\n",
    "    p_positive_given_no_disease = 0.01  # 1 - Specificity\n",
    "    \n",
    "    # Evidence (total probability)\n",
    "    p_positive = (p_positive_given_disease * p_disease + \n",
    "                  p_positive_given_no_disease * p_no_disease)\n",
    "    \n",
    "    # Posterior\n",
    "    p_disease_given_positive = (p_positive_given_disease * p_disease) / p_positive\n",
    "    \n",
    "    print(f\"   P(Disease) = {p_disease:.3f} (prior)\")\n",
    "    print(f\"   P(+|Disease) = {p_positive_given_disease:.3f} (likelihood)\")\n",
    "    print(f\"   P(+|No Disease) = {p_positive_given_no_disease:.3f}\")\n",
    "    print(f\"   P(+) = {p_positive:.3f} (evidence)\")\n",
    "    print(f\"   P(Disease|+) = {p_disease_given_positive:.3f} (posterior)\")\n",
    "    print(f\"   Surprising result: Only {p_disease_given_positive*100:.1f}% chance of disease!\")\n",
    "    \n",
    "    # Visualize the medical test scenario\n",
    "    categories = ['True Positive\\n(Disease & +)', 'False Positive\\n(No Disease & +)', \n",
    "                  'True Negative\\n(No Disease & -)', 'False Negative\\n(Disease & -)']\n",
    "    \n",
    "    values = [p_disease * p_positive_given_disease,\n",
    "              p_no_disease * p_positive_given_no_disease,\n",
    "              p_no_disease * (1 - p_positive_given_no_disease),\n",
    "              p_disease * (1 - p_positive_given_disease)]\n",
    "    \n",
    "    colors = ['green', 'red', 'lightblue', 'orange']\n",
    "    \n",
    "    wedges, texts, autotexts = axes[0, 0].pie(values, labels=categories, colors=colors, \n",
    "                                             autopct='%1.3f', startangle=90)\n",
    "    axes[0, 0].set_title('Medical Test Outcomes\\n(Per 1000 People)')\n",
    "    \n",
    "    # Make text readable\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('black')\n",
    "        autotext.set_fontsize(8)\n",
    "    \n",
    "    # 2. Coin flip with uncertain fairness\n",
    "    print(\"\\n2. Coin Fairness: Learning from Flips\")\n",
    "    print(\"   Prior: Uniform belief about coin bias\")\n",
    "    print(\"   Data: 7 heads out of 10 flips\")\n",
    "    \n",
    "    # Beta-Binomial conjugate prior\n",
    "    # Prior: Beta(1, 1) - uniform\n",
    "    alpha_prior, beta_prior = 1, 1\n",
    "    \n",
    "    # Data\n",
    "    heads, total_flips = 7, 10\n",
    "    tails = total_flips - heads\n",
    "    \n",
    "    # Posterior: Beta(alpha + heads, beta + tails)\n",
    "    alpha_posterior = alpha_prior + heads\n",
    "    beta_posterior = beta_prior + tails\n",
    "    \n",
    "    # Plot prior and posterior\n",
    "    p_values = np.linspace(0, 1, 1000)\n",
    "    prior_dist = beta.pdf(p_values, alpha_prior, beta_prior)\n",
    "    posterior_dist = beta.pdf(p_values, alpha_posterior, beta_posterior)\n",
    "    \n",
    "    axes[0, 1].plot(p_values, prior_dist, 'b--', label='Prior Beta(1,1)', linewidth=2)\n",
    "    axes[0, 1].plot(p_values, posterior_dist, 'r-', label=f'Posterior Beta({alpha_posterior},{beta_posterior})', linewidth=2)\n",
    "    axes[0, 1].axvline(x=0.5, color='gray', linestyle=':', alpha=0.7, label='Fair coin')\n",
    "    axes[0, 1].axvline(x=heads/total_flips, color='orange', linestyle=':', alpha=0.7, label='Observed rate')\n",
    "    axes[0, 1].fill_between(p_values, posterior_dist, alpha=0.3, color='red')\n",
    "    axes[0, 1].set_xlabel('Probability of Heads (Î¸)')\n",
    "    axes[0, 1].set_ylabel('Density')\n",
    "    axes[0, 1].set_title('Bayesian Coin Flip Analysis')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Calculate credible interval\n",
    "    credible_interval = beta.interval(0.95, alpha_posterior, beta_posterior)\n",
    "    posterior_mean = alpha_posterior / (alpha_posterior + beta_posterior)\n",
    "    \n",
    "    print(f\"   Prior: Uniform over [0, 1]\")\n",
    "    print(f\"   Likelihood: Binomial with {heads} heads in {total_flips} flips\")\n",
    "    print(f\"   Posterior mean: {posterior_mean:.3f}\")\n",
    "    print(f\"   95% credible interval: [{credible_interval[0]:.3f}, {credible_interval[1]:.3f}]\")\n",
    "    \n",
    "    # 3. Sequential updating\n",
    "    print(\"\\n3. Sequential Learning: Evidence Accumulation\")\n",
    "    print(\"   How beliefs evolve as we see more data\")\n",
    "    \n",
    "    # Simulate sequential coin flips\n",
    "    true_p = 0.3  # True bias\n",
    "    n_flips = 50\n",
    "    flips = np.random.binomial(1, true_p, n_flips)\n",
    "    \n",
    "    # Track evolution of posterior\n",
    "    posterior_means = []\n",
    "    credible_intervals = []\n",
    "    \n",
    "    alpha, beta_param = 1, 1  # Start with uniform prior\n",
    "    \n",
    "    for i in range(1, n_flips + 1):\n",
    "        # Update with each flip\n",
    "        if flips[i-1] == 1:  # Heads\n",
    "            alpha += 1\n",
    "        else:  # Tails\n",
    "            beta_param += 1\n",
    "        \n",
    "        # Calculate posterior statistics\n",
    "        mean = alpha / (alpha + beta_param)\n",
    "        interval = beta.interval(0.95, alpha, beta_param)\n",
    "        \n",
    "        posterior_means.append(mean)\n",
    "        credible_intervals.append(interval)\n",
    "    \n",
    "    flip_numbers = np.arange(1, n_flips + 1)\n",
    "    posterior_means = np.array(posterior_means)\n",
    "    credible_intervals = np.array(credible_intervals)\n",
    "    \n",
    "    axes[0, 2].plot(flip_numbers, posterior_means, 'b-', linewidth=2, label='Posterior mean')\n",
    "    axes[0, 2].fill_between(flip_numbers, credible_intervals[:, 0], credible_intervals[:, 1], \n",
    "                           alpha=0.3, color='blue', label='95% credible interval')\n",
    "    axes[0, 2].axhline(y=true_p, color='red', linestyle='--', label=f'True value ({true_p})')\n",
    "    axes[0, 2].set_xlabel('Number of Flips')\n",
    "    axes[0, 2].set_ylabel('Estimated P(Heads)')\n",
    "    axes[0, 2].set_title('Sequential Bayesian Learning')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    print(f\"   True bias: {true_p}\")\n",
    "    print(f\"   Final estimate: {posterior_means[-1]:.3f}\")\n",
    "    print(f\"   Final credible interval: [{credible_intervals[-1, 0]:.3f}, {credible_intervals[-1, 1]:.3f}]\")\n",
    "    \n",
    "    # 4. Effect of different priors\n",
    "    print(\"\\n4. Prior Sensitivity Analysis\")\n",
    "    print(\"   How different priors affect conclusions\")\n",
    "    \n",
    "    # Same data: 7 heads in 10 flips\n",
    "    heads, total = 7, 10\n",
    "    \n",
    "    priors = {\n",
    "        'Uniform': (1, 1),\n",
    "        'Optimistic': (2, 1),  # Expect more heads\n",
    "        'Pessimistic': (1, 2),  # Expect more tails\n",
    "        'Strong Fair': (10, 10)  # Strong belief in fairness\n",
    "    }\n",
    "    \n",
    "    p_range = np.linspace(0, 1, 1000)\n",
    "    colors = ['blue', 'green', 'red', 'purple']\n",
    "    \n",
    "    for i, (name, (a_prior, b_prior)) in enumerate(priors.items()):\n",
    "        # Posterior parameters\n",
    "        a_post = a_prior + heads\n",
    "        b_post = b_prior + (total - heads)\n",
    "        \n",
    "        # Plot posterior\n",
    "        posterior = beta.pdf(p_range, a_post, b_post)\n",
    "        axes[1, 0].plot(p_range, posterior, color=colors[i], linewidth=2, label=f'{name} Prior')\n",
    "        \n",
    "        # Calculate statistics\n",
    "        post_mean = a_post / (a_post + b_post)\n",
    "        post_interval = beta.interval(0.95, a_post, b_post)\n",
    "        \n",
    "        print(f\"   {name}: Mean = {post_mean:.3f}, CI = [{post_interval[0]:.3f}, {post_interval[1]:.3f}]\")\n",
    "    \n",
    "    axes[1, 0].axvline(x=0.5, color='gray', linestyle=':', alpha=0.7, label='Fair coin')\n",
    "    axes[1, 0].axvline(x=0.7, color='orange', linestyle=':', alpha=0.7, label='Observed rate')\n",
    "    axes[1, 0].set_xlabel('Probability of Heads')\n",
    "    axes[1, 0].set_ylabel('Posterior Density')\n",
    "    axes[1, 0].set_title('Effect of Different Priors')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Bayesian A/B testing\n",
    "    print(\"\\n5. Bayesian A/B Testing\")\n",
    "    print(\"   Which variant is better?\")\n",
    "    \n",
    "    # A/B test data\n",
    "    visitors_A, conversions_A = 1000, 120\n",
    "    visitors_B, conversions_B = 1100, 140\n",
    "    \n",
    "    # Prior for conversion rates (uniform)\n",
    "    alpha_prior, beta_prior = 1, 1\n",
    "    \n",
    "    # Posteriors\n",
    "    alpha_A = alpha_prior + conversions_A\n",
    "    beta_A = beta_prior + (visitors_A - conversions_A)\n",
    "    \n",
    "    alpha_B = alpha_prior + conversions_B\n",
    "    beta_B = beta_prior + (visitors_B - conversions_B)\n",
    "    \n",
    "    # Sample from posteriors\n",
    "    n_samples = 100000\n",
    "    samples_A = beta.rvs(alpha_A, beta_A, size=n_samples)\n",
    "    samples_B = beta.rvs(alpha_B, beta_B, size=n_samples)\n",
    "    \n",
    "    # Probability that B > A\n",
    "    prob_B_better = np.mean(samples_B > samples_A)\n",
    "    \n",
    "    # Plot posterior distributions\n",
    "    conv_range = np.linspace(0.08, 0.18, 1000)\n",
    "    posterior_A = beta.pdf(conv_range, alpha_A, beta_A)\n",
    "    posterior_B = beta.pdf(conv_range, alpha_B, beta_B)\n",
    "    \n",
    "    axes[1, 1].plot(conv_range, posterior_A, 'b-', linewidth=2, label=f'Variant A ({conversions_A}/{visitors_A})')\n",
    "    axes[1, 1].plot(conv_range, posterior_B, 'r-', linewidth=2, label=f'Variant B ({conversions_B}/{visitors_B})')\n",
    "    axes[1, 1].fill_between(conv_range, posterior_A, alpha=0.3, color='blue')\n",
    "    axes[1, 1].fill_between(conv_range, posterior_B, alpha=0.3, color='red')\n",
    "    axes[1, 1].set_xlabel('Conversion Rate')\n",
    "    axes[1, 1].set_ylabel('Posterior Density')\n",
    "    axes[1, 1].set_title('Bayesian A/B Test Comparison')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    print(f\"   Variant A: {conversions_A}/{visitors_A} = {conversions_A/visitors_A:.3f}\")\n",
    "    print(f\"   Variant B: {conversions_B}/{visitors_B} = {conversions_B/visitors_B:.3f}\")\n",
    "    print(f\"   P(B better than A) = {prob_B_better:.3f}\")\n",
    "    \n",
    "    if prob_B_better > 0.95:\n",
    "        print(f\"   Decision: Strong evidence for B\")\n",
    "    elif prob_B_better > 0.9:\n",
    "        print(f\"   Decision: Moderate evidence for B\")\n",
    "    elif prob_B_better < 0.1:\n",
    "        print(f\"   Decision: Strong evidence for A\")\n",
    "    elif prob_B_better < 0.05:\n",
    "        print(f\"   Decision: Moderate evidence for A\")\n",
    "    else:\n",
    "        print(f\"   Decision: Inconclusive - need more data\")\n",
    "    \n",
    "    # 6. Bayesian model comparison\n",
    "    print(\"\\n6. Bayesian Model Comparison\")\n",
    "    print(\"   Using Bayes factors to compare models\")\n",
    "    \n",
    "    # Generate some data that clearly follows a trend\n",
    "    np.random.seed(42)\n",
    "    x = np.linspace(0, 10, 20)\n",
    "    y_true = 2 * x + 1  # Linear trend\n",
    "    y_observed = y_true + np.random.normal(0, 1, len(x))  # Add noise\n",
    "    \n",
    "    # Model comparison: constant vs linear\n",
    "    # Constant model: y = c\n",
    "    constant_pred = np.mean(y_observed)\n",
    "    constant_mse = np.mean((y_observed - constant_pred)**2)\n",
    "    \n",
    "    # Linear model: y = ax + b\n",
    "    coeffs = np.polyfit(x, y_observed, 1)\n",
    "    linear_pred = coeffs[0] * x + coeffs[1]\n",
    "    linear_mse = np.mean((y_observed - linear_pred)**2)\n",
    "    \n",
    "    # Plot data and models\n",
    "    axes[1, 2].scatter(x, y_observed, alpha=0.7, color='black', label='Observed data')\n",
    "    axes[1, 2].axhline(y=constant_pred, color='red', linestyle='--', linewidth=2, label=f'Constant model (MSE={constant_mse:.2f})')\n",
    "    axes[1, 2].plot(x, linear_pred, color='blue', linewidth=2, label=f'Linear model (MSE={linear_mse:.2f})')\n",
    "    axes[1, 2].plot(x, y_true, color='green', linestyle=':', linewidth=2, label='True relationship')\n",
    "    axes[1, 2].set_xlabel('x')\n",
    "    axes[1, 2].set_ylabel('y')\n",
    "    axes[1, 2].set_title('Bayesian Model Comparison')\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Simple BIC approximation to Bayes factor\n",
    "    n = len(x)\n",
    "    k_constant = 1  # Number of parameters\n",
    "    k_linear = 2\n",
    "    \n",
    "    bic_constant = n * np.log(constant_mse) + k_constant * np.log(n)\n",
    "    bic_linear = n * np.log(linear_mse) + k_linear * np.log(n)\n",
    "    \n",
    "    bayes_factor_approx = np.exp((bic_constant - bic_linear) / 2)\n",
    "    \n",
    "    print(f\"   Constant model MSE: {constant_mse:.3f}\")\n",
    "    print(f\"   Linear model MSE: {linear_mse:.3f}\")\n",
    "    print(f\"   Approximate Bayes factor (Linear/Constant): {bayes_factor_approx:.2f}\")\n",
    "    \n",
    "    if bayes_factor_approx > 10:\n",
    "        print(f\"   Decision: Strong evidence for linear model\")\n",
    "    elif bayes_factor_approx > 3:\n",
    "        print(f\"   Decision: Moderate evidence for linear model\")\n",
    "    else:\n",
    "        print(f\"   Decision: Weak evidence for model preference\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ Key Bayesian Concepts:\")\n",
    "    print(\"â€¢ Prior beliefs get updated with evidence via Bayes' theorem\")\n",
    "    print(\"â€¢ Uncertainty is quantified through probability distributions\")\n",
    "    print(\"â€¢ Conjugate priors make calculations analytically tractable\")\n",
    "    print(\"â€¢ Sequential learning: beliefs evolve as more data arrives\")\n",
    "    print(\"â€¢ Model comparison uses Bayes factors, not just point estimates\")\n",
    "\n",
    "demonstrate_bayes_theorem()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
