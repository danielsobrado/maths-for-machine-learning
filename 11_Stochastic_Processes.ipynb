{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0485c412",
   "metadata": {},
   "source": [
    "# Stochastic Processes for Machine Learning\n",
    "## Time Series Analysis and Sequential Data Modeling\n",
    "\n",
    "Welcome to the **mathematics of randomness over time**! Stochastic processes provide the theoretical foundation for understanding how random systems evolve, making them essential for time series analysis, sequential prediction, and dynamic modeling.\n",
    "\n",
    "### What You'll Master\n",
    "By the end of this notebook, you'll understand:\n",
    "1. **Markov chains** - Memoryless random walks\n",
    "2. **Hidden Markov models** - Observable effects of hidden states\n",
    "3. **Gaussian processes** - Infinite-dimensional Bayesian models\n",
    "4. **Brownian motion** - Continuous random walks\n",
    "5. **Martingales** - Fair games and convergence theory\n",
    "6. **Time series analysis** - ARIMA, state space models\n",
    "\n",
    "### Why This is Essential\n",
    "- **Financial modeling** - Stock prices, risk management\n",
    "- **Signal processing** - Filtering noise from signals\n",
    "- **Natural language** - Sequential text generation\n",
    "- **Reinforcement learning** - Markov decision processes\n",
    "\n",
    "### Real-World Applications\n",
    "- **Speech recognition**: Hidden Markov models for phonemes\n",
    "- **Algorithmic trading**: Mean reversion and momentum strategies\n",
    "- **Weather forecasting**: Stochastic differential equations\n",
    "- **Genomics**: DNA sequence analysis with Markov models\n",
    "\n",
    "Let's dive into the beautiful theory of randomness through time! â°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c90070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from scipy.linalg import expm\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, Matern\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"Set2\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"â° Stochastic Processes toolkit loaded!\")\n",
    "print(\"Ready to model randomness through time!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9401c5a0",
   "metadata": {},
   "source": [
    "## 1. Markov Chains: The Foundation of Sequential Modeling\n",
    "\n",
    "### What is a Markov Chain?\n",
    "A **Markov chain** is a sequence of random events where the probability of each event depends only on the state of the previous event - the **Markov property**.\n",
    "\n",
    "**Mathematical Definition**:\n",
    "```\n",
    "P(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, ..., X_0 = i_0) = P(X_{n+1} = j | X_n = i)\n",
    "```\n",
    "\n",
    "### Key Components\n",
    "1. **State space**: Set of all possible states S = {1, 2, ..., N}\n",
    "2. **Transition matrix**: P_{ij} = P(X_{n+1} = j | X_n = i)\n",
    "3. **Initial distribution**: Ï€_0 = P(X_0 = i)\n",
    "4. **Stationary distribution**: Ï€ such that Ï€ = Ï€P\n",
    "\n",
    "### Properties\n",
    "- **Memoryless**: Future depends only on present, not past\n",
    "- **Time-homogeneous**: Transition probabilities don't change over time\n",
    "- **Ergodic**: Long-run behavior is independent of starting state\n",
    "\n",
    "### Types of States\n",
    "- **Transient**: May never return once left\n",
    "- **Recurrent**: Will return with probability 1\n",
    "- **Absorbing**: Once entered, never left (P_{ii} = 1)\n",
    "- **Periodic**: Returns only at regular intervals\n",
    "\n",
    "### Real-World Examples\n",
    "- **Weather**: Sunny â†’ Cloudy â†’ Rainy â†’ Sunny...\n",
    "- **Stock market**: Bull â†’ Bear â†’ Bull...\n",
    "- **Customer behavior**: Browse â†’ Cart â†’ Purchase â†’ Return...\n",
    "- **Gene expression**: Active â†’ Inactive â†’ Active..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47955760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_markov_chains():\n",
    "    \"\"\"Explore Markov chains with practical examples\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”— Markov Chains: Modeling Sequential Dependencies\")\n",
    "    print(\"=\" * 52)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Simple weather model\n",
    "    print(\"\\n1. Weather Prediction Model\")\n",
    "    print(\"   States: Sunny, Cloudy, Rainy\")\n",
    "    \n",
    "    # Transition matrix\n",
    "    # States: 0=Sunny, 1=Cloudy, 2=Rainy\n",
    "    P_weather = np.array([\n",
    "        [0.7, 0.2, 0.1],  # From Sunny\n",
    "        [0.3, 0.4, 0.3],  # From Cloudy\n",
    "        [0.2, 0.6, 0.2]   # From Rainy\n",
    "    ])\n",
    "    \n",
    "    states = ['Sunny', 'Cloudy', 'Rainy']\n",
    "    \n",
    "    # Visualize transition matrix\n",
    "    im = axes[0, 0].imshow(P_weather, cmap='Blues', aspect='auto')\n",
    "    axes[0, 0].set_xticks(range(3))\n",
    "    axes[0, 0].set_yticks(range(3))\n",
    "    axes[0, 0].set_xticklabels(states)\n",
    "    axes[0, 0].set_yticklabels(states)\n",
    "    axes[0, 0].set_xlabel('To State')\n",
    "    axes[0, 0].set_ylabel('From State')\n",
    "    axes[0, 0].set_title('Weather Transition Matrix')\n",
    "    \n",
    "    # Add probability values\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            axes[0, 0].text(j, i, f'{P_weather[i, j]:.1f}', \n",
    "                           ha='center', va='center', color='white' if P_weather[i, j] > 0.4 else 'black')\n",
    "    \n",
    "    # Calculate stationary distribution\n",
    "    eigenvals, eigenvecs = np.linalg.eig(P_weather.T)\n",
    "    stationary_idx = np.argmin(np.abs(eigenvals - 1.0))\n",
    "    stationary_dist = np.real(eigenvecs[:, stationary_idx])\n",
    "    stationary_dist = stationary_dist / stationary_dist.sum()\n",
    "    \n",
    "    print(f\"   Transition probabilities:\")\n",
    "    for i, state_from in enumerate(states):\n",
    "        print(f\"   {state_from}: {dict(zip(states, P_weather[i]))}\")\n",
    "    print(f\"   Stationary distribution: {dict(zip(states, stationary_dist))}\")\n",
    "    \n",
    "    # 2. Simulate weather sequence\n",
    "    print(\"\\n2. Weather Sequence Simulation\")\n",
    "    \n",
    "    def simulate_markov_chain(P, initial_state, n_steps):\n",
    "        \"\"\"Simulate a Markov chain\"\"\"\n",
    "        states = [initial_state]\n",
    "        current_state = initial_state\n",
    "        \n",
    "        for _ in range(n_steps - 1):\n",
    "            # Sample next state based on transition probabilities\n",
    "            current_state = np.random.choice(len(P), p=P[current_state])\n",
    "            states.append(current_state)\n",
    "        \n",
    "        return np.array(states)\n",
    "    \n",
    "    # Simulate 100 days starting from sunny\n",
    "    weather_sequence = simulate_markov_chain(P_weather, 0, 100)\n",
    "    weather_names = [states[i] for i in weather_sequence]\n",
    "    \n",
    "    # Plot sequence\n",
    "    days = np.arange(len(weather_sequence))\n",
    "    colors = ['gold', 'lightgray', 'blue']\n",
    "    for i, state in enumerate(states):\n",
    "        mask = weather_sequence == i\n",
    "        axes[0, 1].scatter(days[mask], weather_sequence[mask], \n",
    "                         c=colors[i], label=state, alpha=0.7, s=20)\n",
    "    \n",
    "    axes[0, 1].set_xlabel('Day')\n",
    "    axes[0, 1].set_ylabel('Weather State')\n",
    "    axes[0, 1].set_title('100-Day Weather Simulation')\n",
    "    axes[0, 1].set_yticks(range(3))\n",
    "    axes[0, 1].set_yticklabels(states)\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Calculate empirical frequencies\n",
    "    empirical_freq = np.bincount(weather_sequence) / len(weather_sequence)\n",
    "    print(f\"   Empirical frequencies: {dict(zip(states, empirical_freq))}\")\n",
    "    print(f\"   Convergence to stationary: Close? {np.allclose(empirical_freq, stationary_dist, atol=0.1)}\")\n",
    "    \n",
    "    # 3. Convergence to stationary distribution\n",
    "    print(\"\\n3. Convergence Analysis\")\n",
    "    print(\"   How quickly does the chain reach equilibrium?\")\n",
    "    \n",
    "    # Start with extreme initial distribution\n",
    "    initial_dist = np.array([1.0, 0.0, 0.0])  # Always sunny\n",
    "    \n",
    "    # Evolve distribution over time\n",
    "    n_steps = 20\n",
    "    distributions = [initial_dist]\n",
    "    current_dist = initial_dist.copy()\n",
    "    \n",
    "    for step in range(n_steps):\n",
    "        current_dist = current_dist @ P_weather\n",
    "        distributions.append(current_dist.copy())\n",
    "    \n",
    "    distributions = np.array(distributions)\n",
    "    \n",
    "    # Plot convergence\n",
    "    steps = np.arange(n_steps + 1)\n",
    "    for i, state in enumerate(states):\n",
    "        axes[0, 2].plot(steps, distributions[:, i], 'o-', label=f'{state}', linewidth=2)\n",
    "        axes[0, 2].axhline(y=stationary_dist[i], color=axes[0, 2].get_lines()[-1].get_color(), \n",
    "                         linestyle='--', alpha=0.7)\n",
    "    \n",
    "    axes[0, 2].set_xlabel('Time Steps')\n",
    "    axes[0, 2].set_ylabel('Probability')\n",
    "    axes[0, 2].set_title('Convergence to Stationary Distribution')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Calculate mixing time (time to get within 0.01 of stationary)\n",
    "    distances = np.linalg.norm(distributions - stationary_dist, axis=1)\n",
    "    mixing_time = np.argmax(distances < 0.01)\n",
    "    print(f\"   Mixing time (Îµ=0.01): {mixing_time} steps\")\n",
    "    \n",
    "    # 4. Random walk on a graph\n",
    "    print(\"\\n4. Random Walk on a Graph\")\n",
    "    print(\"   Modeling diffusion processes\")\n",
    "    \n",
    "    # Create a simple graph (cycle)\n",
    "    n_nodes = 6\n",
    "    P_graph = np.zeros((n_nodes, n_nodes))\n",
    "    \n",
    "    # Each node connects to its neighbors with equal probability\n",
    "    for i in range(n_nodes):\n",
    "        P_graph[i, (i-1) % n_nodes] = 0.5  # Left neighbor\n",
    "        P_graph[i, (i+1) % n_nodes] = 0.5  # Right neighbor\n",
    "    \n",
    "    # Simulate random walk\n",
    "    walk_length = 1000\n",
    "    walk = simulate_markov_chain(P_graph, 0, walk_length)\n",
    "    \n",
    "    # Plot walk trajectory\n",
    "    time_steps = np.arange(len(walk))\n",
    "    axes[1, 0].plot(time_steps, walk, 'b-', alpha=0.7, linewidth=1)\n",
    "    axes[1, 0].scatter(time_steps[::50], walk[::50], c='red', s=30, zorder=5)\n",
    "    axes[1, 0].set_xlabel('Time Step')\n",
    "    axes[1, 0].set_ylabel('Node')\n",
    "    axes[1, 0].set_title('Random Walk on Cycle Graph')\n",
    "    axes[1, 0].set_yticks(range(n_nodes))\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Calculate visit frequencies\n",
    "    visit_freq = np.bincount(walk, minlength=n_nodes) / len(walk)\n",
    "    stationary_graph = np.ones(n_nodes) / n_nodes  # Uniform for symmetric graph\n",
    "    \n",
    "    print(f\"   Theoretical stationary: uniform ({1/n_nodes:.3f} each)\")\n",
    "    print(f\"   Empirical frequencies: {visit_freq}\")\n",
    "    \n",
    "    # 5. Absorbing Markov chain\n",
    "    print(\"\\n5. Absorbing Markov Chain\")\n",
    "    print(\"   Modeling processes with terminal states\")\n",
    "    \n",
    "    # Simple model: student progress\n",
    "    # States: 0=Freshman, 1=Sophomore, 2=Junior, 3=Senior, 4=Graduate, 5=Dropout\n",
    "    P_student = np.array([\n",
    "        [0.0, 0.8, 0.0, 0.0, 0.0, 0.2],  # Freshman\n",
    "        [0.0, 0.0, 0.7, 0.0, 0.0, 0.3],  # Sophomore\n",
    "        [0.0, 0.0, 0.0, 0.75, 0.0, 0.25], # Junior\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.85, 0.15], # Senior\n",
    "        [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],  # Graduate (absorbing)\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   # Dropout (absorbing)\n",
    "    ])\n",
    "    \n",
    "    student_states = ['Fresh.', 'Soph.', 'Junior', 'Senior', 'Grad.', 'Drop.')\n",
    "    \n",
    "    # Simulate many student careers\n",
    "    n_students = 1000\n",
    "    outcomes = []\n",
    "    \n",
    "    for _ in range(n_students):\n",
    "        # Start as freshman\n",
    "        path = simulate_markov_chain(P_student, 0, 10)  # Max 10 years\n",
    "        \n",
    "        # Find final state\n",
    "        if 4 in path:  # Graduated\n",
    "            outcomes.append('Graduate')\n",
    "        elif 5 in path:  # Dropped out\n",
    "            outcomes.append('Dropout')\n",
    "        else:\n",
    "            outcomes.append('Still studying')\n",
    "    \n",
    "    # Count outcomes\n",
    "    outcome_counts = pd.Series(outcomes).value_counts()\n",
    "    outcome_percentages = outcome_counts / n_students * 100\n",
    "    \n",
    "    # Plot outcomes\n",
    "    outcome_names = outcome_counts.index\n",
    "    colors_outcome = ['green', 'red', 'orange']\n",
    "    axes[1, 1].bar(outcome_names, outcome_percentages, color=colors_outcome, alpha=0.7)\n",
    "    axes[1, 1].set_ylabel('Percentage of Students')\n",
    "    axes[1, 1].set_title('Student Career Outcomes')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for i, (name, pct) in enumerate(zip(outcome_names, outcome_percentages)):\n",
    "        axes[1, 1].text(i, pct + 1, f'{pct:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    print(f\"   Simulation results ({n_students} students):\")\n",
    "    for outcome, pct in outcome_percentages.items():\n",
    "        print(f\"   {outcome}: {pct:.1f}%\")\n",
    "    \n",
    "    # 6. Page rank algorithm\n",
    "    print(\"\\n6. PageRank: Markov Chains for Web Search\")\n",
    "    print(\"   Random surfer model\")\n",
    "    \n",
    "    # Simple web graph\n",
    "    # 4 web pages with links\n",
    "    n_pages = 4\n",
    "    \n",
    "    # Link matrix (who links to whom)\n",
    "    links = np.array([\n",
    "        [0, 1, 1, 0],  # Page 0 links to 1, 2\n",
    "        [1, 0, 1, 1],  # Page 1 links to 0, 2, 3\n",
    "        [1, 0, 0, 1],  # Page 2 links to 0, 3\n",
    "        [0, 1, 1, 0]   # Page 3 links to 1, 2\n",
    "    ])\n",
    "    \n",
    "    # Convert to transition matrix\n",
    "    # Each page distributes its rank equally among its outlinks\n",
    "    P_pagerank = links.astype(float)\n",
    "    row_sums = P_pagerank.sum(axis=1)\n",
    "    P_pagerank = P_pagerank / row_sums[:, np.newaxis]\n",
    "    \n",
    "    # Add damping factor (random jump)\n",
    "    damping = 0.85\n",
    "    n = len(P_pagerank)\n",
    "    P_pagerank = damping * P_pagerank + (1 - damping) / n * np.ones((n, n))\n",
    "    \n",
    "    # Calculate PageRank (stationary distribution)\n",
    "    eigenvals, eigenvecs = np.linalg.eig(P_pagerank.T)\n",
    "    pagerank_idx = np.argmin(np.abs(eigenvals - 1.0))\n",
    "    pagerank = np.real(eigenvecs[:, pagerank_idx])\n",
    "    pagerank = pagerank / pagerank.sum()\n",
    "    \n",
    "    # Plot PageRank scores\n",
    "    pages = [f'Page {i}' for i in range(n_pages)]\n",
    "    bars = axes[1, 2].bar(pages, pagerank, color='skyblue', alpha=0.7)\n",
    "    axes[1, 2].set_ylabel('PageRank Score')\n",
    "    axes[1, 2].set_title('PageRank Algorithm Results')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add score labels\n",
    "    for bar, score in zip(bars, pagerank):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 2].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                       f'{score:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    print(f\"   Link structure:\")\n",
    "    for i, row in enumerate(links):\n",
    "        linked_pages = [j for j, has_link in enumerate(row) if has_link]\n",
    "        print(f\"   Page {i} â†’ Pages {linked_pages}\")\n",
    "    print(f\"   PageRank scores: {dict(zip(pages, pagerank))}\")\n",
    "    print(f\"   Most important page: {pages[np.argmax(pagerank)]}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ Key Markov Chain Concepts:\")\n",
    "    print(\"â€¢ Memoryless property: future depends only on present state\")\n",
    "    print(\"â€¢ Stationary distribution: long-run equilibrium probabilities\")\n",
    "    print(\"â€¢ Mixing time: how quickly the chain forgets its initial state\")\n",
    "    print(\"â€¢ Absorbing states: terminal states that trap the process\")\n",
    "    print(\"â€¢ PageRank: uses Markov chains to rank web pages\")\n",
    "\n",
    "demonstrate_markov_chains()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
