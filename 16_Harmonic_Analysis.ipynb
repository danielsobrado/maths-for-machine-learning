{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e07aa25",
   "metadata": {},
   "source": [
    "# Harmonic Analysis and Signal Processing for Machine Learning\n",
    "## CNNs, Frequency Domain Methods, and Spectral Learning\n",
    "\n",
    "Welcome to the **frequency domain**! Harmonic analysis provides the mathematical foundation for understanding signals, images, and data through their frequency components.\n",
    "\n",
    "### What You'll Master\n",
    "By the end of this notebook, you'll understand:\n",
    "1. **Fourier transforms** - Decomposing signals into frequencies\n",
    "2. **Convolution theorem** - Why CNNs work so well\n",
    "3. **Wavelets** - Multi-scale analysis of signals\n",
    "4. **Spectral methods** - Learning in the frequency domain\n",
    "5. **Graph signal processing** - Harmonic analysis on graphs\n",
    "6. **Time-frequency analysis** - Joint time-frequency representations\n",
    "\n",
    "### Why This is Revolutionary\n",
    "- **CNNs**: Convolution in spatial domain = multiplication in frequency domain\n",
    "- **Efficiency**: FFT makes convolution O(n log n) instead of O(nÂ²)\n",
    "- **Feature extraction**: Frequency components reveal hidden patterns\n",
    "- **Denoising**: Separate signal from noise in frequency domain\n",
    "\n",
    "### Real-World Applications\n",
    "- **Computer vision**: Edge detection, texture analysis, image compression\n",
    "- **Audio processing**: Speech recognition, music analysis, noise reduction\n",
    "- **Medical imaging**: MRI reconstruction, signal enhancement\n",
    "- **Finance**: Time series analysis, market trend detection\n",
    "\n",
    "Let's dive into the frequency domain! ðŸŽµðŸ“Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from scipy import signal, fft\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import pywt\n",
    "from sklearn.datasets import load_digits, make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"ðŸŽµ Harmonic Analysis toolkit loaded!\")\n",
    "print(\"Ready to explore the frequency domain!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3a83f",
   "metadata": {},
   "source": [
    "## 1. Fourier Transforms and Frequency Analysis\n",
    "\n",
    "### The Fourier Transform\n",
    "The **Fourier transform** decomposes a signal into its frequency components:\n",
    "\n",
    "**Continuous Fourier Transform**:\n",
    "```\n",
    "F(Ï‰) = âˆ«_{-âˆž}^{âˆž} f(t) e^{-iÏ‰t} dt\n",
    "```\n",
    "\n",
    "**Discrete Fourier Transform (DFT)**:\n",
    "```\n",
    "X[k] = Î£_{n=0}^{N-1} x[n] e^{-i2Ï€kn/N}\n",
    "```\n",
    "\n",
    "### Key Properties\n",
    "1. **Linearity**: â„±{af + bg} = aâ„±{f} + bâ„±{g}\n",
    "2. **Time shifting**: â„±{f(t-a)} = e^{-iÏ‰a}â„±{f}\n",
    "3. **Frequency shifting**: â„±{e^{iÏ‰â‚€t}f(t)} = F(Ï‰-Ï‰â‚€)\n",
    "4. **Parseval's theorem**: âˆ«|f(t)|Â²dt = (1/2Ï€)âˆ«|F(Ï‰)|Â²dÏ‰\n",
    "\n",
    "### Convolution Theorem\n",
    "The most important property for machine learning:\n",
    "```\n",
    "â„±{f * g} = â„±{f} Â· â„±{g}\n",
    "```\n",
    "**Convolution in time = multiplication in frequency**\n",
    "\n",
    "This is why CNNs are so efficient and why frequency domain methods work!\n",
    "\n",
    "### Fast Fourier Transform (FFT)\n",
    "- **Complexity**: O(N log N) instead of O(NÂ²)\n",
    "- **Algorithm**: Divide-and-conquer using symmetries\n",
    "- **Implementation**: Cooley-Tukey algorithm\n",
    "\n",
    "### Why Frequency Analysis Matters in ML\n",
    "- **Feature extraction**: Frequency components are informative features\n",
    "- **Dimensionality reduction**: Often only a few frequencies matter\n",
    "- **Noise reduction**: Separate signal from noise\n",
    "- **Pattern recognition**: Many patterns have characteristic frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd41aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_fourier_analysis():\n",
    "    \"\"\"Explore Fourier transforms and frequency domain analysis\"\"\"\n",
    "    \n",
    "    print(\"ðŸŽµ Fourier Analysis: Decomposing Signals into Frequencies\")\n",
    "    print(\"=\" * 56)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Basic Fourier transform example\n",
    "    print(\"\\n1. Basic Fourier Transform\")\n",
    "    \n",
    "    # Create a composite signal\n",
    "    t = np.linspace(0, 2, 1000, endpoint=False)\n",
    "    dt = t[1] - t[0]\n",
    "    \n",
    "    # Signal components\n",
    "    f1, f2, f3 = 5, 15, 30  # Frequencies in Hz\n",
    "    signal1 = np.sin(2 * np.pi * f1 * t)\n",
    "    signal2 = 0.5 * np.sin(2 * np.pi * f2 * t)\n",
    "    signal3 = 0.3 * np.sin(2 * np.pi * f3 * t)\n",
    "    noise = 0.1 * np.random.randn(len(t))\n",
    "    \n",
    "    composite_signal = signal1 + signal2 + signal3 + noise\n",
    "    \n",
    "    # Compute FFT\n",
    "    fft_signal = fft.fft(composite_signal)\n",
    "    freqs = fft.fftfreq(len(t), dt)\n",
    "    \n",
    "    # Plot time domain\n",
    "    ax1 = fig.add_subplot(3, 4, 1)\n",
    "    ax1.plot(t[:200], composite_signal[:200], 'b-', linewidth=2, label='Composite')\n",
    "    ax1.plot(t[:200], signal1[:200], 'r--', alpha=0.7, label=f'5 Hz')\n",
    "    ax1.plot(t[:200], signal2[:200], 'g--', alpha=0.7, label=f'15 Hz')\n",
    "    ax1.plot(t[:200], signal3[:200], 'm--', alpha=0.7, label=f'30 Hz')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Amplitude')\n",
    "    ax1.set_title('Time Domain Signal')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot frequency domain\n",
    "    ax2 = fig.add_subplot(3, 4, 2)\n",
    "    magnitude = np.abs(fft_signal)\n",
    "    ax2.plot(freqs[:len(freqs)//2], magnitude[:len(freqs)//2], 'b-', linewidth=2)\n",
    "    ax2.axvline(x=f1, color='red', linestyle='--', alpha=0.7, label=f'{f1} Hz')\n",
    "    ax2.axvline(x=f2, color='green', linestyle='--', alpha=0.7, label=f'{f2} Hz')\n",
    "    ax2.axvline(x=f3, color='magenta', linestyle='--', alpha=0.7, label=f'{f3} Hz')\n",
    "    ax2.set_xlabel('Frequency (Hz)')\n",
    "    ax2.set_ylabel('Magnitude')\n",
    "    ax2.set_title('Frequency Domain (FFT)')\n",
    "    ax2.set_xlim(0, 50)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    print(f\"   Original signal: mix of {f1}, {f2}, {f3} Hz + noise\")\n",
    "    print(f\"   FFT perfectly identifies the frequency components\")\n",
    "    print(f\"   Peak detection in frequency domain reveals hidden structure\")\n",
    "    \n",
    "    # 2. Convolution theorem demonstration\n",
    "    print(\"\\n2. Convolution Theorem: Foundation of CNNs\")\n",
    "    \n",
    "    # Create signals for convolution\n",
    "    n = 128\n",
    "    x = np.zeros(n)\n",
    "    x[n//4:3*n//4] = 1  # Box signal\n",
    "    \n",
    "    # Gaussian kernel (like CNN filter)\n",
    "    kernel_size = 15\n",
    "    kernel = signal.windows.gaussian(kernel_size, std=3)\n",
    "    kernel = kernel / np.sum(kernel)  # Normalize\n",
    "    \n",
    "    # Method 1: Direct convolution\n",
    "    conv_direct = np.convolve(x, kernel, mode='same')\n",
    "    \n",
    "    # Method 2: FFT-based convolution\n",
    "    X_fft = fft.fft(x, n)\n",
    "    K_fft = fft.fft(kernel, n)\n",
    "    conv_fft = np.real(fft.ifft(X_fft * K_fft))\n",
    "    \n",
    "    # Plot convolution comparison\n",
    "    ax3 = fig.add_subplot(3, 4, 3)\n",
    "    ax3.plot(x, 'b-', linewidth=2, label='Original signal')\n",
    "    ax3.plot(conv_direct, 'r-', linewidth=2, label='Direct convolution')\n",
    "    ax3.plot(conv_fft, 'g--', linewidth=2, alpha=0.8, label='FFT convolution')\n",
    "    ax3.set_xlabel('Sample')\n",
    "    ax3.set_ylabel('Amplitude')\n",
    "    ax3.set_title('Convolution: Direct vs FFT')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Show frequency domain multiplication\n",
    "    ax4 = fig.add_subplot(3, 4, 4)\n",
    "    freqs_conv = fft.fftfreq(n)\n",
    "    ax4.plot(freqs_conv[:n//2], np.abs(X_fft)[:n//2], 'b-', label='Signal FFT')\n",
    "    ax4.plot(freqs_conv[:n//2], np.abs(K_fft)[:n//2], 'r-', label='Kernel FFT')\n",
    "    ax4.plot(freqs_conv[:n//2], np.abs(X_fft * K_fft)[:n//2], 'g-', \n",
    "             linewidth=2, label='Product (convolution)')\n",
    "    ax4.set_xlabel('Frequency')\n",
    "    ax4.set_ylabel('Magnitude')\n",
    "    ax4.set_title('Frequency Domain Multiplication')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    print(f\"   Convolution theorem: f * g â†” F Â· G\")\n",
    "    print(f\"   Direct convolution: O(nÂ²), FFT convolution: O(n log n)\")\n",
    "    print(f\"   This is why large CNN kernels use FFT!\")\n",
    "    \n",
    "    # 3. 2D FFT for images\n",
    "    print(\"\\n3. 2D FFT for Image Analysis\")\n",
    "    \n",
    "    # Create a simple image with different frequency components\n",
    "    x_img = np.linspace(-1, 1, 64)\n",
    "    y_img = np.linspace(-1, 1, 64)\n",
    "    X_img, Y_img = np.meshgrid(x_img, y_img)\n",
    "    \n",
    "    # Create image with different frequency patterns\n",
    "    image = (np.sin(5 * np.pi * X_img) * np.cos(3 * np.pi * Y_img) + \n",
    "             0.5 * np.sin(15 * np.pi * X_img) + \n",
    "             0.3 * np.cos(10 * np.pi * Y_img))\n",
    "    \n",
    "    # Add some noise\n",
    "    image += 0.2 * np.random.randn(*image.shape)\n",
    "    \n",
    "    # 2D FFT\n",
    "    fft_image = fft.fft2(image)\n",
    "    fft_magnitude = np.abs(fft.fftshift(fft_image))\n",
    "    \n",
    "    # Plot original image\n",
    "    ax5 = fig.add_subplot(3, 4, 5)\n",
    "    im1 = ax5.imshow(image, cmap='viridis', aspect='equal')\n",
    "    ax5.set_title('Original Image')\n",
    "    ax5.axis('off')\n",
    "    plt.colorbar(im1, ax=ax5, shrink=0.8)\n",
    "    \n",
    "    # Plot FFT magnitude\n",
    "    ax6 = fig.add_subplot(3, 4, 6)\n",
    "    im2 = ax6.imshow(np.log(1 + fft_magnitude), cmap='hot', aspect='equal')\n",
    "    ax6.set_title('2D FFT Magnitude (log scale)')\n",
    "    ax6.axis('off')\n",
    "    plt.colorbar(im2, ax=ax6, shrink=0.8)\n",
    "    \n",
    "    print(f\"   2D FFT reveals spatial frequency content\")\n",
    "    print(f\"   Bright spots = dominant spatial frequencies\")\n",
    "    print(f\"   Center = low frequencies, edges = high frequencies\")\n",
    "    \n",
    "    # 4. Frequency-based filtering\n",
    "    print(\"\\n4. Frequency Domain Filtering\")\n",
    "    \n",
    "    # Low-pass filter (remove high frequencies)\n",
    "    def low_pass_filter(fft_img, cutoff=0.2):\n",
    "        h, w = fft_img.shape\n",
    "        center_h, center_w = h // 2, w // 2\n",
    "        Y, X = np.ogrid[:h, :w]\n",
    "        dist = np.sqrt((X - center_w)**2 + (Y - center_h)**2)\n",
    "        mask = dist <= cutoff * min(h, w) / 2\n",
    "        filtered_fft = fft_img.copy()\n",
    "        filtered_fft[~mask] = 0\n",
    "        return filtered_fft\n",
    "    \n",
    "    # High-pass filter (remove low frequencies)\n",
    "    def high_pass_filter(fft_img, cutoff=0.1):\n",
    "        h, w = fft_img.shape\n",
    "        center_h, center_w = h // 2, w // 2\n",
    "        Y, X = np.ogrid[:h, :w]\n",
    "        dist = np.sqrt((X - center_w)**2 + (Y - center_h)**2)\n",
    "        mask = dist > cutoff * min(h, w) / 2\n",
    "        filtered_fft = fft_img.copy()\n",
    "        filtered_fft[~mask] = 0\n",
    "        return filtered_fft\n",
    "    \n",
    "    # Apply filters\n",
    "    fft_shifted = fft.fftshift(fft_image)\n",
    "    low_passed_fft = low_pass_filter(fft_shifted)\n",
    "    high_passed_fft = high_pass_filter(fft_shifted)\n",
    "    \n",
    "    # Convert back to spatial domain\n",
    "    low_passed = np.real(fft.ifft2(fft.ifftshift(low_passed_fft)))\n",
    "    high_passed = np.real(fft.ifft2(fft.ifftshift(high_passed_fft)))\n",
    "    \n",
    "    # Plot filtered results\n",
    "    ax7 = fig.add_subplot(3, 4, 7)\n",
    "    im3 = ax7.imshow(low_passed, cmap='viridis', aspect='equal')\n",
    "    ax7.set_title('Low-pass Filtered (Smooth)')\n",
    "    ax7.axis('off')\n",
    "    plt.colorbar(im3, ax=ax7, shrink=0.8)\n",
    "    \n",
    "    ax8 = fig.add_subplot(3, 4, 8)\n",
    "    im4 = ax8.imshow(high_passed, cmap='viridis', aspect='equal')\n",
    "    ax8.set_title('High-pass Filtered (Edges)')\n",
    "    ax8.axis('off')\n",
    "    plt.colorbar(im4, ax=ax8, shrink=0.8)\n",
    "    \n",
    "    print(f\"   Low-pass filter: Keeps low frequencies (smooth features)\")\n",
    "    print(f\"   High-pass filter: Keeps high frequencies (edges, details)\")\n",
    "    print(f\"   Same principle as CNN pooling and convolution!\")\n",
    "    \n",
    "    # 5. Spectral analysis of real data\n",
    "    print(\"\\n5. Spectral Analysis for Feature Extraction\")\n",
    "    \n",
    "    # Load digit dataset\n",
    "    digits = load_digits()\n",
    "    sample_digit = digits.images[0]  # First digit (8x8 image)\n",
    "    \n",
    "    # Compute 2D FFT of digit\n",
    "    digit_fft = fft.fft2(sample_digit)\n",
    "    digit_magnitude = np.abs(fft.fftshift(digit_fft))\n",
    "    \n",
    "    # Plot original digit\n",
    "    ax9 = fig.add_subplot(3, 4, 9)\n",
    "    im5 = ax9.imshow(sample_digit, cmap='gray', aspect='equal')\n",
    "    ax9.set_title(f'Digit: {digits.target[0]}')\n",
    "    ax9.axis('off')\n",
    "    plt.colorbar(im5, ax=ax9, shrink=0.8)\n",
    "    \n",
    "    # Plot FFT\n",
    "    ax10 = fig.add_subplot(3, 4, 10)\n",
    "    im6 = ax10.imshow(np.log(1 + digit_magnitude), cmap='hot', aspect='equal')\n",
    "    ax10.set_title('Digit FFT Spectrum')\n",
    "    ax10.axis('off')\n",
    "    plt.colorbar(im6, ax=ax10, shrink=0.8)\n",
    "    \n",
    "    # Extract spectral features for classification\n",
    "    def extract_spectral_features(images):\n",
    "        \"\"\"Extract frequency domain features from images\"\"\"\n",
    "        features = []\n",
    "        for img in images:\n",
    "            # 2D FFT\n",
    "            fft_img = fft.fft2(img)\n",
    "            magnitude = np.abs(fft_img)\n",
    "            \n",
    "            # Extract features: low frequency energy, high frequency energy, etc.\n",
    "            total_energy = np.sum(magnitude**2)\n",
    "            low_freq_energy = np.sum(magnitude[:2, :2]**2)\n",
    "            high_freq_energy = np.sum(magnitude[-2:, -2:]**2)\n",
    "            \n",
    "            # Radial frequency profile\n",
    "            h, w = magnitude.shape\n",
    "            center_h, center_w = h // 2, w // 2\n",
    "            Y, X = np.ogrid[:h, :w]\n",
    "            dist = np.sqrt((X - center_w)**2 + (Y - center_h)**2)\n",
    "            \n",
    "            radial_profile = []\n",
    "            for r in range(1, min(h, w) // 2):\n",
    "                mask = (dist >= r-0.5) & (dist < r+0.5)\n",
    "                if np.any(mask):\n",
    "                    radial_profile.append(np.mean(magnitude[mask]))\n",
    "            \n",
    "            # Combine features\n",
    "            spectral_features = [\n",
    "                total_energy,\n",
    "                low_freq_energy / total_energy,\n",
    "                high_freq_energy / total_energy\n",
    "            ] + radial_profile[:3]  # First few radial components\n",
    "            \n",
    "            features.append(spectral_features)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    # Extract features for a subset of digits\n",
    "    n_samples = 500\n",
    "    sample_images = digits.images[:n_samples]\n",
    "    sample_targets = digits.target[:n_samples]\n",
    "    \n",
    "    spectral_features = extract_spectral_features(sample_images)\n",
    "    \n",
    "    # Simple classification using spectral features\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        spectral_features, sample_targets, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train classifier\n",
    "    rf_spectral = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "    rf_spectral.fit(X_train, y_train)\n",
    "    spectral_accuracy = rf_spectral.score(X_test, y_test)\n",
    "    \n",
    "    # Compare with pixel-based features\n",
    "    pixel_features = sample_images.reshape(n_samples, -1)\n",
    "    X_train_pixel, X_test_pixel, _, _ = train_test_split(\n",
    "        pixel_features, sample_targets, test_size=0.3, random_state=42)\n",
    "    \n",
    "    rf_pixel = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "    rf_pixel.fit(X_train_pixel, y_train)\n",
    "    pixel_accuracy = rf_pixel.score(X_test_pixel, y_test)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    ax11 = fig.add_subplot(3, 4, 11)\n",
    "    feature_names = ['Total Energy', 'Low Freq %', 'High Freq %', 'Radial 1', 'Radial 2', 'Radial 3']\n",
    "    importances = rf_spectral.feature_importances_\n",
    "    ax11.bar(range(len(importances)), importances)\n",
    "    ax11.set_xticks(range(len(importances)))\n",
    "    ax11.set_xticklabels(feature_names, rotation=45, ha='right')\n",
    "    ax11.set_ylabel('Importance')\n",
    "    ax11.set_title('Spectral Feature Importance')\n",
    "    ax11.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot accuracy comparison\n",
    "    ax12 = fig.add_subplot(3, 4, 12)\n",
    "    methods = ['Spectral Features', 'Pixel Features']\n",
    "    accuracies = [spectral_accuracy, pixel_accuracy]\n",
    "    bars = ax12.bar(methods, accuracies, color=['orange', 'skyblue'])\n",
    "    ax12.set_ylabel('Accuracy')\n",
    "    ax12.set_title('Classification Accuracy')\n",
    "    ax12.set_ylim(0, 1)\n",
    "    \n",
    "    # Add accuracy values on bars\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        ax12.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                 f'{acc:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    ax12.grid(True, alpha=0.3)\n",
    "    \n",
    "    print(f\"   Spectral features: {len(spectral_features[0])} dimensions vs {pixel_features.shape[1]} pixels\")\n",
    "    print(f\"   Spectral accuracy: {spectral_accuracy:.3f}\")\n",
    "    print(f\"   Pixel accuracy: {pixel_accuracy:.3f}\")\n",
    "    print(f\"   Frequency domain often provides more informative features!\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'composite_signal': composite_signal,\n",
    "        'fft_signal': fft_signal,\n",
    "        'freqs': freqs,\n",
    "        'image': image,\n",
    "        'fft_image': fft_image,\n",
    "        'spectral_features': spectral_features,\n",
    "        'spectral_accuracy': spectral_accuracy,\n",
    "        'pixel_accuracy': pixel_accuracy\n",
    "    }\n",
    "\n",
    "fourier_results = demonstrate_fourier_analysis()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
