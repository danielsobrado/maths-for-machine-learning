{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca6b11d",
   "metadata": {},
   "source": [
    "# Graph Theory for Machine Learning\n",
    "## Graph Neural Networks and Network Analysis\n",
    "\n",
    "Welcome to the **mathematics of relationships and connections**! Graph theory provides the mathematical framework for understanding networks, relationships, and structured data that goes beyond traditional grid-based representations.\n",
    "\n",
    "### What You'll Master\n",
    "By the end of this notebook, you'll understand:\n",
    "1. **Graph fundamentals** - Vertices, edges, and graph properties\n",
    "2. **Graph matrices** - Adjacency, Laplacian, and incidence matrices\n",
    "3. **Spectral graph theory** - Eigenvalues reveal graph structure\n",
    "4. **Graph neural networks** - Learning on non-Euclidean data\n",
    "5. **Network analysis** - Centrality, communities, and connectivity\n",
    "6. **Random walks on graphs** - Diffusion and PageRank algorithms\n",
    "\n",
    "### Why This is Revolutionary\n",
    "- **Social networks** - Understanding influence and information spread\n",
    "- **Molecular analysis** - Drug discovery through graph neural networks\n",
    "- **Recommendation systems** - User-item interaction graphs\n",
    "- **Knowledge graphs** - Reasoning over structured knowledge\n",
    "\n",
    "### Real-World Applications\n",
    "- **Social media**: Friend recommendation, community detection\n",
    "- **Biology**: Protein folding, molecular property prediction\n",
    "- **Transportation**: Route optimization, traffic flow analysis\n",
    "- **Finance**: Fraud detection, risk assessment through transaction networks\n",
    "\n",
    "Let's explore the beautiful mathematics of networks and connections! üï∏Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc82383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from scipy import sparse, linalg\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"Set1\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"üï∏Ô∏è Graph Theory toolkit loaded!\")\n",
    "print(\"Ready to analyze networks and relationships!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e309e06d",
   "metadata": {},
   "source": [
    "## 1. Graph Fundamentals and Representations\n",
    "\n",
    "### What is a Graph?\n",
    "A **graph** G = (V, E) consists of:\n",
    "- **V**: Set of vertices (nodes) representing entities\n",
    "- **E**: Set of edges connecting vertices, representing relationships\n",
    "\n",
    "### Types of Graphs\n",
    "1. **Undirected**: Edges have no direction (friendship networks)\n",
    "2. **Directed**: Edges have direction (web page links, Twitter follows)\n",
    "3. **Weighted**: Edges have weights (distance, strength of connection)\n",
    "4. **Unweighted**: All edges are equal\n",
    "\n",
    "### Graph Matrices\n",
    "**Adjacency Matrix A**:\n",
    "```\n",
    "A[i,j] = { w_ij  if edge (i,j) exists with weight w_ij\n",
    "         { 0     otherwise\n",
    "```\n",
    "\n",
    "**Degree Matrix D**:\n",
    "```\n",
    "D[i,i] = degree of vertex i = Œ£‚±º A[i,j]\n",
    "D[i,j] = 0 for i ‚â† j\n",
    "```\n",
    "\n",
    "**Graph Laplacian L**:\n",
    "```\n",
    "L = D - A\n",
    "```\n",
    "\n",
    "**Normalized Laplacian LÃÉ**:\n",
    "```\n",
    "LÃÉ = D^(-1/2) L D^(-1/2) = I - D^(-1/2) A D^(-1/2)\n",
    "```\n",
    "\n",
    "### Why Laplacians Matter\n",
    "- **Spectrum reveals structure**: Eigenvalues encode connectivity\n",
    "- **Number of connected components**: Number of zero eigenvalues\n",
    "- **Graph cuts**: Second smallest eigenvalue (Fiedler value)\n",
    "- **Diffusion processes**: Heat equation on graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_graph_fundamentals():\n",
    "    \"\"\"Explore fundamental concepts in graph theory\"\"\"\n",
    "    \n",
    "    print(\"üìä Graph Theory Fundamentals\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Basic graph types\n",
    "    print(\"\\n1. Graph Types and Representations\")\n",
    "    \n",
    "    # Create different types of graphs\n",
    "    graphs = {}\n",
    "    \n",
    "    # Undirected graph\n",
    "    G_undirected = nx.Graph()\n",
    "    G_undirected.add_edges_from([(0, 1), (1, 2), (2, 3), (3, 0), (1, 3), (0, 2)])\n",
    "    graphs['Undirected'] = G_undirected\n",
    "    \n",
    "    # Directed graph\n",
    "    G_directed = nx.DiGraph()\n",
    "    G_directed.add_edges_from([(0, 1), (1, 2), (2, 3), (3, 0), (1, 3)])\n",
    "    graphs['Directed'] = G_directed\n",
    "    \n",
    "    # Weighted graph\n",
    "    G_weighted = nx.Graph()\n",
    "    G_weighted.add_weighted_edges_from([(0, 1, 0.5), (1, 2, 1.2), (2, 3, 0.8), \n",
    "                                       (3, 0, 1.5), (1, 3, 0.3)])\n",
    "    graphs['Weighted'] = G_weighted\n",
    "    \n",
    "    # Plot different graph types\n",
    "    positions = {0: (0, 1), 1: (1, 1), 2: (1, 0), 3: (0, 0)}\n",
    "    \n",
    "    for i, (graph_type, G) in enumerate(graphs.items()):\n",
    "        if i < 3:\n",
    "            ax = axes[0, i]\n",
    "            \n",
    "            if graph_type == 'Weighted':\n",
    "                # Draw with edge weights\n",
    "                nx.draw(G, positions, ax=ax, with_labels=True, node_color='lightblue',\n",
    "                       node_size=500, font_size=16, font_weight='bold')\n",
    "                edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "                nx.draw_networkx_edge_labels(G, positions, edge_labels, ax=ax)\n",
    "            else:\n",
    "                nx.draw(G, positions, ax=ax, with_labels=True, node_color='lightblue',\n",
    "                       node_size=500, font_size=16, font_weight='bold',\n",
    "                       arrows=True if graph_type == 'Directed' else False)\n",
    "            \n",
    "            ax.set_title(f'{graph_type} Graph')\n",
    "            ax.axis('off')\n",
    "    \n",
    "    print(f\"   Undirected: {G_undirected.number_of_nodes()} nodes, {G_undirected.number_of_edges()} edges\")\n",
    "    print(f\"   Directed: {G_directed.number_of_nodes()} nodes, {G_directed.number_of_edges()} edges\")\n",
    "    print(f\"   Weighted: {G_weighted.number_of_nodes()} nodes, {G_weighted.number_of_edges()} edges\")\n",
    "    \n",
    "    # 2. Graph matrices\n",
    "    print(\"\\n2. Graph Matrix Representations\")\n",
    "    \n",
    "    # Use the undirected graph for matrix analysis\n",
    "    G = G_undirected\n",
    "    n = G.number_of_nodes()\n",
    "    \n",
    "    # Adjacency matrix\n",
    "    A = nx.adjacency_matrix(G).toarray()\n",
    "    \n",
    "    # Degree matrix\n",
    "    degrees = dict(G.degree())\n",
    "    D = np.diag([degrees[i] for i in range(n)])\n",
    "    \n",
    "    # Laplacian matrix\n",
    "    L = D - A\n",
    "    \n",
    "    # Normalized Laplacian\n",
    "    D_inv_sqrt = np.diag([1/np.sqrt(degrees[i]) if degrees[i] > 0 else 0 for i in range(n)])\n",
    "    L_norm = D_inv_sqrt @ L @ D_inv_sqrt\n",
    "    \n",
    "    # Visualize matrices\n",
    "    matrices = [('Adjacency (A)', A), ('Degree (D)', D), ('Laplacian (L)', L)]\n",
    "    \n",
    "    for i, (name, matrix) in enumerate(matrices):\n",
    "        if i < 3:\n",
    "            ax = axes[1, i]\n",
    "            im = ax.imshow(matrix, cmap='RdBu', aspect='equal')\n",
    "            ax.set_title(name)\n",
    "            ax.set_xticks(range(n))\n",
    "            ax.set_yticks(range(n))\n",
    "            \n",
    "            # Add values to matrix\n",
    "            for row in range(n):\n",
    "                for col in range(n):\n",
    "                    ax.text(col, row, f'{matrix[row, col]:.0f}', \n",
    "                           ha='center', va='center', \n",
    "                           color='white' if abs(matrix[row, col]) > matrix.max()/2 else 'black')\n",
    "            \n",
    "            plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "    \n",
    "    print(f\"   Matrix dimensions: {n}√ó{n}\")\n",
    "    print(f\"   Adjacency matrix sum: {A.sum()} (twice the number of edges)\")\n",
    "    print(f\"   Degree matrix trace: {np.trace(D)} (sum of all degrees)\")\n",
    "    print(f\"   Laplacian properties: symmetric, positive semidefinite\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return G, A, L, L_norm\n",
    "\n",
    "G_demo, A_demo, L_demo, L_norm_demo = demonstrate_graph_fundamentals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734dd55d",
   "metadata": {},
   "source": [
    "## 2. Spectral Graph Theory\n",
    "\n",
    "### The Magic of Graph Spectra\n",
    "The **eigenvalues and eigenvectors** of graph matrices reveal deep structural properties:\n",
    "\n",
    "**Laplacian Spectrum Properties**:\n",
    "1. **Œª‚ÇÅ = 0**: Always zero with eigenvector of all ones\n",
    "2. **Œª‚ÇÇ (Fiedler value)**: Controls connectivity - larger means more connected\n",
    "3. **Number of 0 eigenvalues**: Number of connected components\n",
    "4. **Largest eigenvalue**: Related to maximum degree\n",
    "\n",
    "**Graph Cuts and Clustering**:\n",
    "The Fiedler vector (eigenvector of Œª‚ÇÇ) provides optimal graph bisection:\n",
    "```\n",
    "Ratio Cut = Œ£·µ¢‚±º A[i,j] |f·µ¢ - f‚±º|¬≤ / (|S| √ó |SÃÑ|)\n",
    "```\n",
    "\n",
    "**Cheeger's Inequality**:\n",
    "Connects algebraic (eigenvalues) and combinatorial (cuts) properties:\n",
    "```\n",
    "Œª‚ÇÇ/2 ‚â§ h(G) ‚â§ ‚àö(2Œª‚ÇÇ)\n",
    "```\n",
    "where h(G) is the Cheeger constant (isoperimetric number).\n",
    "\n",
    "### Applications in Machine Learning\n",
    "- **Spectral clustering**: Use eigenvectors for dimensionality reduction\n",
    "- **Graph signal processing**: Fourier transform on graphs\n",
    "- **Manifold learning**: Laplacian eigenmaps\n",
    "- **Graph neural networks**: Spectral convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_spectral_graph_theory():\n",
    "    \"\"\"Explore spectral properties of graphs\"\"\"\n",
    "    \n",
    "    print(\"üåà Spectral Graph Theory: Eigenvalues Reveal Structure\")\n",
    "    print(\"=\" * 58)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Eigenvalues of different graph structures\n",
    "    print(\"\\n1. Graph Structure and Eigenvalue Patterns\")\n",
    "    \n",
    "    graph_types = {\n",
    "        'Path': nx.path_graph(10),\n",
    "        'Cycle': nx.cycle_graph(10),\n",
    "        'Complete': nx.complete_graph(10),\n",
    "        'Star': nx.star_graph(9),  # 9 + 1 center = 10 nodes\n",
    "        'Grid': nx.grid_2d_graph(3, 3),\n",
    "        'Random': nx.erdos_renyi_graph(10, 0.3, seed=42)\n",
    "    }\n",
    "    \n",
    "    eigenvalue_data = {}\n",
    "    \n",
    "    for name, G in graph_types.items():\n",
    "        # Get Laplacian matrix\n",
    "        L = nx.laplacian_matrix(G).toarray()\n",
    "        \n",
    "        # Compute eigenvalues\n",
    "        eigenvals = np.linalg.eigvals(L)\n",
    "        eigenvals = np.sort(eigenvals)\n",
    "        eigenvalue_data[name] = eigenvals\n",
    "        \n",
    "        print(f\"   {name} graph: Œª‚ÇÇ = {eigenvals[1]:.3f}, max Œª = {eigenvals[-1]:.3f}\")\n",
    "    \n",
    "    # Plot eigenvalue spectra\n",
    "    for i, (name, eigenvals) in enumerate(list(eigenvalue_data.items())[:3]):\n",
    "        ax = axes[0, i]\n",
    "        ax.stem(range(len(eigenvals)), eigenvals, basefmt=' ')\n",
    "        ax.set_xlabel('Eigenvalue Index')\n",
    "        ax.set_ylabel('Eigenvalue')\n",
    "        ax.set_title(f'{name} Graph Spectrum')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Highlight the Fiedler value\n",
    "        ax.scatter([1], [eigenvals[1]], color='red', s=100, zorder=5, label='Fiedler value')\n",
    "        ax.legend()\n",
    "    \n",
    "    # 2. Graph clustering using spectral methods\n",
    "    print(\"\\n2. Spectral Clustering\")\n",
    "    print(\"   Using Fiedler vector for graph partitioning\")\n",
    "    \n",
    "    # Create a graph with clear community structure\n",
    "    G_communities = nx.Graph()\n",
    "    \n",
    "    # Community 1: nodes 0-4\n",
    "    for i in range(5):\n",
    "        for j in range(i+1, 5):\n",
    "            if np.random.random() > 0.3:  # Dense connections within community\n",
    "                G_communities.add_edge(i, j)\n",
    "    \n",
    "    # Community 2: nodes 5-9\n",
    "    for i in range(5, 10):\n",
    "        for j in range(i+1, 10):\n",
    "            if np.random.random() > 0.3:  # Dense connections within community\n",
    "                G_communities.add_edge(i, j)\n",
    "    \n",
    "    # Few connections between communities\n",
    "    G_communities.add_edge(2, 7)  # Bridge connection\n",
    "    G_communities.add_edge(4, 5)  # Another bridge\n",
    "    \n",
    "    # Get Laplacian and compute Fiedler vector\n",
    "    L_communities = nx.laplacian_matrix(G_communities).toarray()\n",
    "    eigenvals, eigenvecs = np.linalg.eigh(L_communities)\n",
    "    fiedler_vector = eigenvecs[:, 1]  # Second eigenvector\n",
    "    \n",
    "    # Partition based on sign of Fiedler vector\n",
    "    partition = fiedler_vector > 0\n",
    "    \n",
    "    # Plot original graph with spectral clustering\n",
    "    pos = nx.spring_layout(G_communities, seed=42)\n",
    "    \n",
    "    # Color nodes by partition\n",
    "    node_colors = ['red' if partition[i] else 'blue' for i in range(len(partition))]\n",
    "    \n",
    "    nx.draw(G_communities, pos, ax=axes[1, 0], node_color=node_colors,\n",
    "           with_labels=True, node_size=300, font_size=10)\n",
    "    axes[1, 0].set_title('Spectral Clustering Result')\n",
    "    \n",
    "    print(f\"   Fiedler value: {eigenvals[1]:.3f}\")\n",
    "    print(f\"   Partition 1 (red): {np.where(partition)[0]}\")\n",
    "    print(f\"   Partition 2 (blue): {np.where(~partition)[0]}\")\n",
    "    \n",
    "    # 3. Graph signal processing\n",
    "    print(\"\\n3. Graph Signal Processing\")\n",
    "    print(\"   Fourier transform on graphs using Laplacian eigenvectors\")\n",
    "    \n",
    "    # Create a path graph for clear demonstration\n",
    "    G_path = nx.path_graph(20)\n",
    "    L_path = nx.laplacian_matrix(G_path).toarray()\n",
    "    \n",
    "    # Compute full eigendecomposition\n",
    "    eigenvals_path, eigenvecs_path = np.linalg.eigh(L_path)\n",
    "    \n",
    "    # Create a signal on the graph (smooth vs. rough)\n",
    "    nodes = np.arange(20)\n",
    "    \n",
    "    # Smooth signal\n",
    "    signal_smooth = np.sin(2 * np.pi * nodes / 20) + 0.5 * np.sin(4 * np.pi * nodes / 20)\n",
    "    \n",
    "    # Add some noise (rough signal)\n",
    "    signal_noisy = signal_smooth + 0.3 * np.random.randn(20)\n",
    "    \n",
    "    # Graph Fourier transform\n",
    "    signal_freq_smooth = eigenvecs_path.T @ signal_smooth\n",
    "    signal_freq_noisy = eigenvecs_path.T @ signal_noisy\n",
    "    \n",
    "    # Plot signals\n",
    "    axes[1, 1].plot(nodes, signal_smooth, 'b-o', linewidth=2, markersize=4, label='Smooth signal')\n",
    "    axes[1, 1].plot(nodes, signal_noisy, 'r-s', linewidth=1, markersize=3, alpha=0.7, label='Noisy signal')\n",
    "    axes[1, 1].set_xlabel('Node Index')\n",
    "    axes[1, 1].set_ylabel('Signal Value')\n",
    "    axes[1, 1].set_title('Signals on Path Graph')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot frequency domain\n",
    "    axes[1, 2].stem(eigenvals_path, np.abs(signal_freq_smooth), basefmt=' ', \n",
    "                   label='Smooth signal', linefmt='b-', markerfmt='bo')\n",
    "    axes[1, 2].stem(eigenvals_path, np.abs(signal_freq_noisy), basefmt=' ',\n",
    "                   label='Noisy signal', linefmt='r-', markerfmt='rs')\n",
    "    axes[1, 2].set_xlabel('Eigenvalue (Frequency)')\n",
    "    axes[1, 2].set_ylabel('|Fourier Coefficient|')\n",
    "    axes[1, 2].set_title('Graph Fourier Transform')\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Graph signal denoising\n",
    "    # Keep only low-frequency components (small eigenvalues)\n",
    "    cutoff = 2.0\n",
    "    signal_freq_filtered = signal_freq_noisy.copy()\n",
    "    signal_freq_filtered[eigenvals_path > cutoff] = 0\n",
    "    \n",
    "    # Inverse graph Fourier transform\n",
    "    signal_denoised = eigenvecs_path @ signal_freq_filtered\n",
    "    \n",
    "    print(f\"   Original signal energy: {np.linalg.norm(signal_smooth):.3f}\")\n",
    "    print(f\"   Noisy signal energy: {np.linalg.norm(signal_noisy):.3f}\")\n",
    "    print(f\"   Denoised signal energy: {np.linalg.norm(signal_denoised):.3f}\")\n",
    "    print(f\"   Denoising error: {np.linalg.norm(signal_denoised - signal_smooth):.3f}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return G_communities, fiedler_vector, partition\n",
    "\n",
    "G_comm, fiedler_vec, spectral_partition = demonstrate_spectral_graph_theory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1e807",
   "metadata": {},
   "source": [
    "## 3. Graph Neural Networks (GNNs)\n",
    "\n",
    "### The Revolution: Learning on Graphs\n",
    "Traditional neural networks work on **Euclidean data** (images, sequences). Graph Neural Networks extend this to **non-Euclidean data** where relationships matter more than spatial structure.\n",
    "\n",
    "### Core GNN Operations\n",
    "**Message Passing Framework**:\n",
    "1. **Message**: m^(l)_{ij} = Message(h^(l)_i, h^(l)_j, e_{ij})\n",
    "2. **Aggregation**: m^(l)_i = Aggregate({m^(l)_{ji} : j ‚àà N(i)})\n",
    "3. **Update**: h^(l+1)_i = Update(h^(l)_i, m^(l)_i)\n",
    "\n",
    "### Types of GNNs\n",
    "**Graph Convolutional Networks (GCN)**:\n",
    "```\n",
    "H^(l+1) = œÉ(DÃÉ^(-1/2) √É DÃÉ^(-1/2) H^(l) W^(l))\n",
    "```\n",
    "where √É = A + I (adjacency + self-loops)\n",
    "\n",
    "**GraphSAGE (Sample and Aggregate)**:\n",
    "```\n",
    "h^(l+1)_v = œÉ(W^(l) ¬∑ CONCAT(h^(l)_v, AGG({h^(l)_u : u ‚àà N(v)})))\n",
    "```\n",
    "\n",
    "**Graph Attention Networks (GAT)**:\n",
    "```\n",
    "Œ±_{ij} = softmax(LeakyReLU(a^T [W h_i || W h_j]))\n",
    "h'_i = œÉ(Œ£‚±º Œ±_{ij} W h_j)\n",
    "```\n",
    "\n",
    "### Why GNNs Work\n",
    "- **Permutation invariance**: Output doesn't depend on node ordering\n",
    "- **Locality**: Information propagates through graph structure\n",
    "- **Weight sharing**: Same function applied at each node\n",
    "- **Inductive bias**: Graph structure guides learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_graph_neural_networks():\n",
    "    \"\"\"Explore Graph Neural Network concepts and implementations\"\"\"\n",
    "    \n",
    "    print(\"üß† Graph Neural Networks: Learning on Non-Euclidean Data\")\n",
    "    print(\"=\" * 57)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Simple GCN implementation\n",
    "    print(\"\\n1. Graph Convolutional Network (GCN) Implementation\")\n",
    "    \n",
    "    class SimpleGCN:\n",
    "        def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "            \"\"\"Simple GCN implementation\"\"\"\n",
    "            self.W1 = np.random.randn(input_dim, hidden_dim) * 0.1\n",
    "            self.W2 = np.random.randn(hidden_dim, output_dim) * 0.1\n",
    "            self.b1 = np.zeros(hidden_dim)\n",
    "            self.b2 = np.zeros(output_dim)\n",
    "        \n",
    "        def relu(self, x):\n",
    "            return np.maximum(0, x)\n",
    "        \n",
    "        def softmax(self, x):\n",
    "            exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "            return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "        \n",
    "        def forward(self, A_norm, X):\n",
    "            \"\"\"Forward pass: H^(l+1) = œÉ(A_norm H^(l) W^(l))\"\"\"\n",
    "            # First GCN layer\n",
    "            H1 = A_norm @ X @ self.W1 + self.b1\n",
    "            H1 = self.relu(H1)\n",
    "            \n",
    "            # Second GCN layer\n",
    "            H2 = A_norm @ H1 @ self.W2 + self.b2\n",
    "            return self.softmax(H2)\n",
    "    \n",
    "    # Create a synthetic graph for node classification\n",
    "    np.random.seed(42)\n",
    "    n_nodes = 20\n",
    "    n_features = 5\n",
    "    n_classes = 3\n",
    "    \n",
    "    # Create graph with community structure\n",
    "    G_gcn = nx.Graph()\n",
    "    \n",
    "    # Three communities\n",
    "    communities = [list(range(0, 7)), list(range(7, 14)), list(range(14, 20))]\n",
    "    \n",
    "    # Dense connections within communities\n",
    "    for community in communities:\n",
    "        for i in community:\n",
    "            for j in community:\n",
    "                if i < j and np.random.random() > 0.4:\n",
    "                    G_gcn.add_edge(i, j)\n",
    "    \n",
    "    # Sparse connections between communities\n",
    "    G_gcn.add_edge(3, 10)  # Bridge 1\n",
    "    G_gcn.add_edge(6, 15)  # Bridge 2\n",
    "    G_gcn.add_edge(12, 17) # Bridge 3\n",
    "    \n",
    "    # Create adjacency matrix\n",
    "    A = nx.adjacency_matrix(G_gcn).toarray()\n",
    "    \n",
    "    # Add self-loops and normalize\n",
    "    A_tilde = A + np.eye(n_nodes)\n",
    "    D_tilde = np.diag(np.sum(A_tilde, axis=1))\n",
    "    D_inv_sqrt = np.diag(1.0 / np.sqrt(np.diag(D_tilde)))\n",
    "    A_norm = D_inv_sqrt @ A_tilde @ D_inv_sqrt\n",
    "    \n",
    "    # Create node features (community-based)\n",
    "    X = np.random.randn(n_nodes, n_features)\n",
    "    for i, community in enumerate(communities):\n",
    "        # Add community-specific bias to features\n",
    "        community_bias = np.random.randn(n_features) * 2\n",
    "        for node in community:\n",
    "            X[node] += community_bias\n",
    "    \n",
    "    # True labels based on communities\n",
    "    y_true = np.zeros(n_nodes, dtype=int)\n",
    "    for i, community in enumerate(communities):\n",
    "        for node in community:\n",
    "            y_true[node] = i\n",
    "    \n",
    "    # Initialize and run GCN\n",
    "    gcn = SimpleGCN(n_features, 8, n_classes)\n",
    "    y_pred_probs = gcn.forward(A_norm, X)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    # Visualize graph with predictions\n",
    "    pos = nx.spring_layout(G_gcn, seed=42)\n",
    "    colors = ['red', 'blue', 'green']\n",
    "    \n",
    "    # True labels\n",
    "    node_colors_true = [colors[y_true[i]] for i in range(n_nodes)]\n",
    "    nx.draw(G_gcn, pos, ax=axes[0, 0], node_color=node_colors_true,\n",
    "           with_labels=True, node_size=300, font_size=8)\n",
    "    axes[0, 0].set_title('True Community Labels')\n",
    "    \n",
    "    # Predicted labels\n",
    "    node_colors_pred = [colors[y_pred[i]] for i in range(n_nodes)]\n",
    "    nx.draw(G_gcn, pos, ax=axes[0, 1], node_color=node_colors_pred,\n",
    "           with_labels=True, node_size=300, font_size=8)\n",
    "    axes[0, 1].set_title('GCN Predicted Labels')\n",
    "    \n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    print(f\"   Nodes: {n_nodes}, Features: {n_features}, Classes: {n_classes}\")\n",
    "    print(f\"   GCN accuracy: {accuracy:.3f}\")\n",
    "    print(f\"   True communities: {communities}\")\n",
    "    \n",
    "    # 2. Attention mechanism visualization\n",
    "    print(\"\\n2. Graph Attention Mechanism\")\n",
    "    print(\"   How nodes decide which neighbors to focus on\")\n",
    "    \n",
    "    def compute_attention_weights(h_i, h_j, W, a):\n",
    "        \"\"\"Compute attention weights between nodes i and j\"\"\"\n",
    "        # Transform features\n",
    "        Wh_i = W @ h_i\n",
    "        Wh_j = W @ h_j\n",
    "        \n",
    "        # Attention mechanism\n",
    "        concat_features = np.concatenate([Wh_i, Wh_j])\n",
    "        attention_score = a.T @ concat_features\n",
    "        return attention_score\n",
    "    \n",
    "    # Simple attention example with 5 nodes\n",
    "    n_att_nodes = 5\n",
    "    feature_dim = 3\n",
    "    hidden_dim = 4\n",
    "    \n",
    "    # Random node features\n",
    "    H = np.random.randn(n_att_nodes, feature_dim)\n",
    "    # Attention parameters\n",
    "    W_att = np.random.randn(hidden_dim, feature_dim) * 0.1\n",
    "    a_att = np.random.randn(2 * hidden_dim) * 0.1\n",
    "    \n",
    "    # Create a small complete graph for attention demo\n",
    "    G_att = nx.complete_graph(n_att_nodes)\n",
    "    A_att = nx.adjacency_matrix(G_att).toarray()\n",
    "    \n",
    "    # Compute attention weights\n",
    "    attention_matrix = np.zeros((n_att_nodes, n_att_nodes))\n",
    "    \n",
    "    for i in range(n_att_nodes):\n",
    "        attention_scores = []\n",
    "        neighbors = [j for j in range(n_att_nodes) if A_att[i, j] == 1 or i == j]\n",
    "        \n",
    "        for j in neighbors:\n",
    "            score = compute_attention_weights(H[i], H[j], W_att, a_att)\n",
    "            attention_scores.append((j, score))\n",
    "        \n",
    "        # Softmax normalization\n",
    "        scores = np.array([score for _, score in attention_scores])\n",
    "        scores_normalized = np.exp(scores) / np.sum(np.exp(scores))\n",
    "        \n",
    "        for idx, (j, _) in enumerate(attention_scores):\n",
    "            attention_matrix[i, j] = scores_normalized[idx]\n",
    "    \n",
    "    # Visualize attention matrix\n",
    "    im = axes[0, 2].imshow(attention_matrix, cmap='Blues', aspect='auto')\n",
    "    axes[0, 2].set_xlabel('Target Node')\n",
    "    axes[0, 2].set_ylabel('Source Node')\n",
    "    axes[0, 2].set_title('Attention Weight Matrix')\n",
    "    axes[0, 2].set_xticks(range(n_att_nodes))\n",
    "    axes[0, 2].set_yticks(range(n_att_nodes))\n",
    "    \n",
    "    # Add values to attention matrix\n",
    "    for i in range(n_att_nodes):\n",
    "        for j in range(n_att_nodes):\n",
    "            if attention_matrix[i, j] > 0:\n",
    "                axes[0, 2].text(j, i, f'{attention_matrix[i, j]:.2f}',\n",
    "                               ha='center', va='center', fontsize=8,\n",
    "                               color='white' if attention_matrix[i, j] > 0.5 else 'black')\n",
    "    \n",
    "    plt.colorbar(im, ax=axes[0, 2], shrink=0.8)\n",
    "    \n",
    "    print(f\"   Attention nodes: {n_att_nodes}\")\n",
    "    print(f\"   Each row sums to 1: {[f'{row.sum():.3f}' for row in attention_matrix]}\")\n",
    "    \n",
    "    # 3. Message passing visualization\n",
    "    print(\"\\n3. Message Passing in GNNs\")\n",
    "    print(\"   How information flows through the graph\")\n",
    "    \n",
    "    # Create a simple star graph for clear message passing demo\n",
    "    G_star = nx.star_graph(4)  # Center node + 4 outer nodes\n",
    "    pos_star = nx.spring_layout(G_star, seed=42)\n",
    "    \n",
    "    # Simulate message passing for 3 layers\n",
    "    n_star_nodes = 5\n",
    "    initial_features = np.random.randn(n_star_nodes, 1)\n",
    "    A_star = nx.adjacency_matrix(G_star).toarray().astype(float)\n",
    "    \n",
    "    # Add self-loops and normalize\n",
    "    A_star_norm = A_star + np.eye(n_star_nodes)\n",
    "    D_star = np.diag(np.sum(A_star_norm, axis=1))\n",
    "    A_star_norm = np.linalg.inv(D_star) @ A_star_norm\n",
    "    \n",
    "    # Track features through layers\n",
    "    features_layers = [initial_features.copy()]\n",
    "    current_features = initial_features.copy()\n",
    "    \n",
    "    for layer in range(3):\n",
    "        # Simple message passing: aggregate neighbors\n",
    "        current_features = A_star_norm @ current_features\n",
    "        features_layers.append(current_features.copy())\n",
    "    \n",
    "    # Plot message passing evolution\n",
    "    layer_indices = [0, 1, 2, 3]\n",
    "    for layer_idx in layer_indices[:3]:\n",
    "        ax = axes[1, layer_idx]\n",
    "        \n",
    "        # Node colors based on feature values\n",
    "        feature_values = features_layers[layer_idx].flatten()\n",
    "        node_colors = plt.cm.RdYlBu((feature_values - feature_values.min()) / \n",
    "                                   (feature_values.max() - feature_values.min()))\n",
    "        \n",
    "        nx.draw(G_star, pos_star, ax=ax, node_color=node_colors,\n",
    "               with_labels=True, node_size=400, font_size=12)\n",
    "        ax.set_title(f'Layer {layer_idx} Features')\n",
    "        \n",
    "        # Add feature values as text\n",
    "        for node, (x, y) in pos_star.items():\n",
    "            ax.text(x, y-0.15, f'{feature_values[node]:.2f}',\n",
    "                   ha='center', va='top', fontsize=8, weight='bold')\n",
    "    \n",
    "    print(f\"   Star graph: 1 center node, 4 outer nodes\")\n",
    "    print(f\"   Initial center feature: {initial_features[0, 0]:.3f}\")\n",
    "    print(f\"   Final center feature: {features_layers[-1][0, 0]:.3f}\")\n",
    "    print(f\"   Information aggregated from all neighbors through layers\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return G_gcn, gcn, attention_matrix\n",
    "\n",
    "G_gnn, gnn_model, att_matrix = demonstrate_graph_neural_networks()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
